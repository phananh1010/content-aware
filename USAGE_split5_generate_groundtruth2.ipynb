{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: create customed anno, anno_dict from raw csv\n",
    "#input is csv annotation file\n",
    "#output is anno, anno_dict\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import namespace\n",
    "import log_parser\n",
    "import youtubebb_converter\n",
    "import imagenet_converter\n",
    "import dataset_generator\n",
    "import metric_map\n",
    "import predictor\n",
    "import utils\n",
    "\n",
    "\n",
    "reload(utils)\n",
    "reload(log_parser)\n",
    "reload(namespace)\n",
    "reload(youtubebb_converter)\n",
    "reload(predictor)\n",
    "reload(dataset_generator)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "def plot_bbox(rgb_img, pred_item, color_idx=0):\n",
    "    _, cid, score, xmin, ymin, xmax, ymax = pred_item\n",
    "    cname = namespace.CLASS_INDEX[cid]\n",
    "    \n",
    "    scale = np.array(rgb_img.shape[1::-1]+rgb_img.shape[1::-1])#[1::-1])\n",
    "    label_name = cname\n",
    "    display_txt = '%s: %.2f'%(label_name, score)\n",
    "    detection = np.array([xmin, ymin, xmax, ymax])\n",
    "    pt = detection * scale#(detection*scale).cpu().numpy()\n",
    "    coords = (pt[0], pt[1]), pt[2]-pt[0]+1, pt[3]-pt[1]+1\n",
    "    \n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, 21)).tolist()\n",
    "    color = colors[0]\n",
    "\n",
    "    plt.imshow(rgb_img)\n",
    "    \n",
    "    if len(pred_item) > 0:\n",
    "        currentAxis = plt.gca()\n",
    "        currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=color, linewidth=2))\n",
    "    plt.axis('off')\n",
    "    plt.figure()\n",
    "    \n",
    "def get_groundtruth_item(img_filepath, vid_filepath, pred):\n",
    "    #TODO: \n",
    "    img = cv2.imread(img_filepath, cv2.IMREAD_COLOR)\n",
    "    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    dtoken, ftoken = utils.get_dirtoken_from_vidpath(vid_filepath), utils.get_filetoken_from_imgpath(vid_filepath, img_filepath)\n",
    "    gt_list = yanno_dict[dtoken][ftoken]\n",
    "    \n",
    "    pred_list = pred.detect(img)\n",
    "    if pred_list == []:\n",
    "        #print ('DETECTED NOTHING for {}, SKIPPED'.format(img_filepath))\n",
    "        return 0.0#gt_list[0], pred_list, 0.0\n",
    "    #plot_bbox(rgb_img, pred_list[0])\n",
    "    #plot_bbox(rgb_img, gt_list[0], color_idx=10)\n",
    "\n",
    "    score = mAP.score(pred_list, gt_list)\n",
    "    return score#gt_list[0], pred_list, score\n",
    "\n",
    "def get_all_frameversions(frame_filepath, vid_filepath, pred):\n",
    "    #TODO: for a given frame in max bitrate & max resolution (x1080_b1024), \n",
    "    #retrive corresponding frames in other bitrates & resolutions\n",
    "    #INPUT: a filepath to frame in highest res & bit\n",
    "    #OUTPUT: grouthtruth for everyone\n",
    "    \n",
    "    frame_filemask = frame_filepath.replace(namespace.FRAMEVERSION_BEST, '*')\n",
    "    result = []\n",
    "    for img_filepath in glob.glob(frame_filemask):\n",
    "        result.append(get_groundtruth_item(img_filepath, vid_filepath, pred))\n",
    "    return result\n",
    "\n",
    "def generate_viditem_groundtruth(vidpath, pred):\n",
    "    #TODO: generate ground truth from given video path\n",
    "    #INPUT: path to video, predictor\n",
    "    #OUTPUT: dict structure store groundtruth all frames for that video\n",
    "    result = {}\n",
    "    framemask = os.path.splitext(vidpath)[0] + '/' + namespace.FRAMEVERSION_BEST + '/??????.jpg'\n",
    "    for framepath in glob.glob(framemask): #go over all frame item in the best verion\n",
    "        #for each best frame item, collect score over all of its versions\n",
    "        #print item\n",
    "        try:\n",
    "            gt_list = get_all_frameversions(framepath, vidpath, pred)\n",
    "        except:\n",
    "            print 'ERROR: ', framepath, vidpath\n",
    "            raise\n",
    "        result[framepath] = gt_list\n",
    "    return vidpath, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights into state dict...\n",
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u9167/.conda/envs/env_torch/lib/python2.7/site-packages/ipykernel_launcher.py:17: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n"
     ]
    }
   ],
   "source": [
    "#in order for log_parser to work, previous steps are assumed to be taken.\n",
    "#see https://github.com/phananh1010/content-aware/tree/master/scripts for further detail\n",
    "\n",
    "LogParser = log_parser.LogParser()\n",
    "vidinfo_dict= LogParser.load_metainfo_dict()\n",
    "\n",
    "YConverter = youtubebb_converter.YoutubeBBConverter(vidinfo_dict)\n",
    "mAP = metric_map.mAP()\n",
    "Pred  = predictor.Predictor()\n",
    "\n",
    "#only run once to create processed Youtube annotation dict, write to FILEPATH_YOUTUBE_YANNODICT\n",
    "#YConverter.parse_annotation(namespace.FILEPATH_YOUTUBE_RAWANNOCSV, namespace.FILEPATH_YOUTUBE_YANNODICT)\n",
    "yanno, yanno_dict = YConverter.load_annotation(namespace.FILEPATH_YOUTUBE_YANNODICT)\n",
    "DatGen = dataset_generator.DatasetGenerator(YConverter, mAP, Pred, yanno_dict)\n",
    "\n",
    "#for debuging purpose only\n",
    "df = pd.DataFrame.from_csv('./data/YOUTUBE_data/yt_bb_detection_train.csv', header=None)\n",
    "df1 = pd.read_pickle('./data/YOUTUBE_data/yt_bb_detection_train_filtered.pkl.gz', compression='gzip')\n",
    "                            #./data/YOUTUBE_data/yt_bb_detection_train_filtered.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "#from ID=15, list all videos (use bash to generate)\n",
    "#from videos list, call python code to generate groundtruth\n",
    "\n",
    "#the python code: receive a filepath to the videos, iterate over images\n",
    "#ID = 15\n",
    "#PYTHON CODE\n",
    "#INPUT: filepath to video\n",
    "#OUTPUT: ground truth array for every single frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/u9167/content_aware/data/YOUTUBE_data/videos'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "namespace.DIRPATH_YOUTUBE_VIDEOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKIPPED /home/u9167/content_aware/data/YOUTUBE_data/videos/15/3zcr2YpUk1M+15+0.mp4\n",
      "SKIPPED /home/u9167/content_aware/data/YOUTUBE_data/videos/15/43TG-8oaSXg+15+0.mp4\n",
      "SKIPPED /home/u9167/content_aware/data/YOUTUBE_data/videos/15/4Ht9Cn1u9sw+15+0.mp4\n",
      "SKIPPED /home/u9167/content_aware/data/YOUTUBE_data/videos/15/4UtuV5h1IWY+15+0.mp4\n",
      "SKIPPED /home/u9167/content_aware/data/YOUTUBE_data/videos/15/4z93xWvsjNk+15+0.mp4\n",
      "SKIPPED /home/u9167/content_aware/data/YOUTUBE_data/videos/15/6kgOuDfwx6Q+15+0.mp4\n",
      "SKIPPED /home/u9167/content_aware/data/YOUTUBE_data/videos/15/7m_Fvo-uWK8+15+0.mp4\n",
      "SKIPPED /home/u9167/content_aware/data/YOUTUBE_data/videos/15/AdEH-oHs1Qo+15+0.mp4\n",
      "SKIPPED /home/u9167/content_aware/data/YOUTUBE_data/videos/15/AdEH-oHs1Qo+15+1.mp4\n",
      "SKIPPED /home/u9167/content_aware/data/YOUTUBE_data/videos/15/AdEH-oHs1Qo+15+2.mp4\n",
      "SKIPPED /home/u9167/content_aware/data/YOUTUBE_data/videos/15/AdEH-oHs1Qo+15+3.mp4\n",
      "SKIPPED /home/u9167/content_aware/data/YOUTUBE_data/videos/15/Es46YsO9J5M+15+0.mp4\n",
      "SKIPPED /home/u9167/content_aware/data/YOUTUBE_data/videos/15/HkzYNIDq0q4+15+0.mp4\n",
      "SKIPPED /home/u9167/content_aware/data/YOUTUBE_data/videos/15/IAwKojHnvtU+15+0.mp4\n",
      "SKIPPED /home/u9167/content_aware/data/YOUTUBE_data/videos/15/Jc9PdqC1rpg+15+0.mp4\n",
      "SKIPPED /home/u9167/content_aware/data/YOUTUBE_data/videos/15/Jnysuevt_4A+15+0.mp4\n",
      "SKIPPED /home/u9167/content_aware/data/YOUTUBE_data/videos/15/Jnysuevt_4A+15+1.mp4\n",
      "SKIPPED /home/u9167/content_aware/data/YOUTUBE_data/videos/15/K5q4FoXnLwI+15+0.mp4\n",
      "SKIPPED /home/u9167/content_aware/data/YOUTUBE_data/videos/15/KFdkB3xOTTQ+15+0.mp4\n",
      "SKIPPED /home/u9167/content_aware/data/YOUTUBE_data/videos/15/NmX6VPSbaEw+15+0.mp4\n",
      "processing /home/u9167/content_aware/data/YOUTUBE_data/videos/15/OZF-eZK1aXE+15+0.mp4\n",
      "processing /home/u9167/content_aware/data/YOUTUBE_data/videos/15/WybwAHSpQdY+15+0.mp4\n"
     ]
    }
   ],
   "source": [
    "ID = 15\n",
    "\n",
    "_GROUNDTRUTH_DICT_TEMPLATE_ = namespace.DIRPATH_YOUTUBE_DATA + '/' + '_groundtruth_dict_{}_'\n",
    "GROUNDTRUTH_DICT_FILEPATH = _GROUNDTRUTH_DICT_TEMPLATE_.format(ID)\n",
    "vidmask = namespace.DIRPATH_YOUTUBE_VIDEOS + '/{}/'.format(ID) + '*.mp4'\n",
    "\n",
    "gt_dict = {}\n",
    "try:\n",
    "    gt_dict = pickle.load(open(GROUNDTRUTH_DICT_FILEPATH))\n",
    "except:\n",
    "    print 'ERROR, no file found, will use default empty dic'\n",
    "    \n",
    "\n",
    "for vid_filepath in glob.glob(vidmask):\n",
    "    if vid_filepath in gt_dict: \n",
    "        print (\"SKIPPED {}\".format(vid_filepath))\n",
    "        continue\n",
    "    print ('processing {}'.format(vid_filepath))\n",
    "    k, v = generate_viditem_groundtruth(vid_filepath, Pred)\n",
    "    gt_dict[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(gt_dict, open(GROUNDTRUTH_DICT_FILEPATH, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################END OF EXAMPLE USAGE#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################DEBUGGING PART###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0/frames_x1080_b1024k/000001.jpg\n",
      "/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0/frames_x1080_b1024k/000002.jpg\n",
      "/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0/frames_x1080_b1024k/000003.jpg\n",
      "/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0/frames_x1080_b1024k/000004.jpg\n",
      "/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0/frames_x1080_b1024k/000005.jpg\n",
      "/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0/frames_x1080_b1024k/000006.jpg\n",
      "/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0/frames_x1080_b1024k/000007.jpg\n",
      "/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0/frames_x1080_b1024k/000008.jpg\n",
      "/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0/frames_x1080_b1024k/000009.jpg\n",
      "/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0/frames_x1080_b1024k/000010.jpg\n",
      "/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0/frames_x1080_b1024k/000011.jpg\n",
      "/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0/frames_x1080_b1024k/000012.jpg\n",
      "/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0/frames_x1080_b1024k/000013.jpg\n",
      "/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0/frames_x1080_b1024k/000014.jpg\n",
      "/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0/frames_x1080_b1024k/000015.jpg\n",
      "/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0/frames_x1080_b1024k/000016.jpg\n",
      "/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0/frames_x1080_b1024k/000000.jpg\n"
     ]
    }
   ],
   "source": [
    "vidpath = '/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0.mp4'\n",
    "\n",
    "#given video, output frames\n",
    "\n",
    "framemask = os.path.splitext(vidpath)[0] + '/' + namespace.FRAMEVERSION_BEST + '/*.jpg'\n",
    "for item in glob.glob(framemask):\n",
    "    print item\n",
    "#framemask_filepath = '/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0.mp4'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1,\n",
       " 0.1,\n",
       " 0.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_filepath = '/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0/frames_x1080_b1024k/000003.jpg'\n",
    "vid_filepath = '/home/u9167/content_aware/data/YOUTUBE_data/videos/1/7sq8O2KpCf0+1+0.mp4'\n",
    "\n",
    "vid_filepath = './data/YOUTUBE_data/videos/15/7m_Fvo-uWK8+15+0.mp4'\n",
    "frame_filepath = './data/YOUTUBE_data/videos/15/7m_Fvo-uWK8+15+0/frames_x1080_b1024k/000003.jpg'\n",
    "\n",
    "frame_filepath = '/home/u9167/content_aware/data/YOUTUBE_data/videos/10/8q0FNaWFBjw+10+0/frames_x1080_b1024k/000005.jpg'\n",
    "vid_filepath = '/home/u9167/content_aware/data/YOUTUBE_data/videos/10/8q0FNaWFBjw+10+0/'\n",
    "\n",
    "frame_filepath = '/home/u9167/content_aware/data/YOUTUBE_data/videos/19/ShDBzVI0_Io+19+0/frames_x1080_b1024k/000005.jpg'\n",
    "vid_filepath = '/home/u9167/content_aware/data/YOUTUBE_data/videos/19/ShDBzVI0_Io+19+0.mp4'\n",
    "\n",
    "\n",
    "#given framepath & vidpath, generate groundtruth\n",
    "get_all_frameversions(frame_filepath, vid_filepath, Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4Ht9Cn1u9sw+9+0+10000001'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_filepath = '/home/u9167/content_aware/data/YOUTUBE_data/videos/15/4Ht9Cn1u9sw+15+0/frames_x1080_b1024k/10000001.jpg'\n",
    "vid_filepath = '/home/u9167/content_aware/data/YOUTUBE_data/videos/15/4Ht9Cn1u9sw+15+0.mp4'\n",
    "\n",
    "utils.get_filetoken_from_imgpath(vid_filepath, img_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_torch)",
   "language": "python",
   "name": "env_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
